{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f91c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in ./anaconda3/lib/python3.10/site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./anaconda3/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=9cf311905c3df40da959a987e4fbb23852b3a4c726245c9d23352375828c7bc2\n",
      "  Stored in directory: /Users/tusharnetake/Library/Caches/pip/wheels/e4/62/1d/d4d1bc4f33350ff84227f89b258edb552d604138e3739f5c83\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.10/site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018c127",
   "metadata": {},
   "source": [
    "### 1) Write a python program to display all the header tags from wikipedia.org and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d341fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Wiki page main headings\n",
      "0                      Main Page\n",
      "1           Welcome to Wikipedia\n",
      "2  From today's featured article\n",
      "3               Did you know ...\n",
      "4                    In the news\n",
      "5                    On this day\n",
      "6       Today's featured picture\n",
      "7       Other areas of Wikipedia\n",
      "8    Wikipedia's sister projects\n",
      "9            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def get_wiki_Header():\n",
    "    wiki_content = requests.get('https://en.wikipedia.org/wiki/Main_Page').content\n",
    "\n",
    "    if wiki_content:\n",
    "        soup = BeautifulSoup(wiki_content, 'html.parser')\n",
    "        headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        header_tags = []\n",
    "        for header in headers:\n",
    "            header_tags.append(header.text.strip())\n",
    "        return header_tags\n",
    "\n",
    "\n",
    "wiki_headers = get_wiki_Header()\n",
    "\n",
    "if header_tags:\n",
    "        data = {'Wiki page main headings': wiki_headers}\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3f99d",
   "metadata": {},
   "source": [
    "### 2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adf80548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_1 = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6196f75",
   "metadata": {},
   "source": [
    "### 3)Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data framea) \n",
    "a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7272c562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team Matches Points  \\\n",
      "0        India\\nIND      55  6,640   \n",
      "1    Australia\\nAUS      42  4,926   \n",
      "2  South Africa\\nSA      34  3,750   \n",
      "3     Pakistan\\nPAK      36  3,922   \n",
      "4   New Zealand\\nNZ      43  4,399   \n",
      "5      England\\nENG      38  3,777   \n",
      "6     Sri Lanka\\nSL      47  4,134   \n",
      "7   Bangladesh\\nBAN      44  3,836   \n",
      "8  Afghanistan\\nAFG      30  2,533   \n",
      "9   West Indies\\nWI      38  2,582   \n",
      "\n",
      "                                              Rating  \n",
      "0  \\n                            121\\n           ...  \n",
      "1                                                117  \n",
      "2                                                110  \n",
      "3                                                109  \n",
      "4                                                102  \n",
      "5                                                 99  \n",
      "6                                                 88  \n",
      "7                                                 87  \n",
      "8                                                 84  \n",
      "9                                                 68  \n"
     ]
    }
   ],
   "source": [
    "#a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating. \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def odi_teams_ranking():\n",
    "    ranking_content = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\").content\n",
    "\n",
    "    if ranking_content:\n",
    "        soup = BeautifulSoup(ranking_content, 'html.parser')\n",
    "        \n",
    "        teams_data = []\n",
    "        table = soup.find('table', class_='table')\n",
    "        rows = table.find_all('tr')[1:11] \n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            team_name = columns[1].text.strip()\n",
    "            matches = columns[2].text\n",
    "            points = columns[3].text\n",
    "            rating = columns[4].text\n",
    "            teams_data.append({'Team': team_name, 'Matches': matches, 'Points': points, 'Rating': rating})\n",
    "\n",
    "        teams_df = pd.DataFrame(teams_data)\n",
    "        print(teams_df)\n",
    "        \n",
    "odi_teams_ranking()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9833e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 ODI Batsmen:\n",
      "                  Player Team   Rating\n",
      "0           Shubman Gill  IND  \\n826\\n\n",
      "1             Babar Azam  PAK      824\n",
      "2            Virat Kohli  IND      791\n",
      "3           Rohit Sharma  IND      769\n",
      "4        Quinton de Kock   SA      760\n",
      "5         Daryl Mitchell   NZ      750\n",
      "6           David Warner  AUS      745\n",
      "7  Rassie van der Dussen   SA      735\n",
      "8           Harry Tector  IRE      729\n",
      "9            Dawid Malan  ENG      729\n"
     ]
    }
   ],
   "source": [
    "#b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "\n",
    "def scrape_odi_batsmen():\n",
    "    batsman_ranking = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\").content\n",
    "    if batsman_ranking:\n",
    "        soup = BeautifulSoup(batsman_ranking, 'html.parser')\n",
    "        \n",
    "        batsmen_data = []\n",
    "        table = soup.find('table', class_='table')\n",
    "        rows = table.find_all('tr')[1:11]\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            player_name = columns[1].text.strip()\n",
    "            team = columns[2].text.strip()\n",
    "            rating = columns[3].text\n",
    "            batsmen_data.append({'Player': player_name, 'Team': team, 'Rating': rating})\n",
    "\n",
    "        batsmen_df = pd.DataFrame(batsmen_data)\n",
    "        print(\"\\nTop 10 ODI Batsmen:\")\n",
    "        print(batsmen_df)\n",
    "\n",
    "scrape_odi_batsmen()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "faa893ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 ODI Bowlers:\n",
      "           Player Team   Rating\n",
      "0  Keshav Maharaj   SA  \\n741\\n\n",
      "1  Josh Hazlewood  AUS      703\n",
      "2  Mohammed Siraj  IND      699\n",
      "3  Jasprit Bumrah  IND      685\n",
      "4      Adam Zampa  AUS      675\n",
      "5     Rashid Khan  AFG      667\n",
      "6   Kuldeep Yadav  IND      667\n",
      "7     Trent Boult   NZ      663\n",
      "8  Shaheen Afridi  PAK      650\n",
      "9  Mohammad Shami  IND      648\n"
     ]
    }
   ],
   "source": [
    "#c) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_odi_bowlers():\n",
    "    bowling_ranking = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\").content\n",
    "\n",
    "    if bowling_ranking:\n",
    "        soup = BeautifulSoup(bowling_ranking, 'html.parser')\n",
    "        \n",
    "        bowlers_data = []\n",
    "        table = soup.find('table', class_='table')\n",
    "        rows = table.find_all('tr')[1:11]\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            player_name = columns[1].text.strip()\n",
    "            team = columns[2].text.strip()\n",
    "            rating = columns[3].text\n",
    "            bowlers_data.append({'Player': player_name, 'Team': team, 'Rating': rating})\n",
    "\n",
    "        bowlers_df = pd.DataFrame(bowlers_data)\n",
    "        print(\"\\nTop 10 ODI Bowlers:\")\n",
    "        print(bowlers_df)\n",
    "\n",
    "scrape_odi_bowlers()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199ca62",
   "metadata": {},
   "source": [
    "### 4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea1f065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Women's ODI Teams:\n",
      "               Team Matches Points  \\\n",
      "0    Australia\\nAUS      21  3,429   \n",
      "1      England\\nENG      23  2,991   \n",
      "2  South Africa\\nSA      21  2,446   \n",
      "3        India\\nIND      18  1,745   \n",
      "4   New Zealand\\nNZ      21  2,014   \n",
      "5   West Indies\\nWI      20  1,768   \n",
      "6     Sri Lanka\\nSL       9    714   \n",
      "7   Bangladesh\\nBAN      14  1,074   \n",
      "8     Thailand\\nTHA      11    753   \n",
      "9     Pakistan\\nPAK      24  1,602   \n",
      "\n",
      "                                              Rating  \n",
      "0  \\n                            163\\n           ...  \n",
      "1                                                130  \n",
      "2                                                116  \n",
      "3                                                 97  \n",
      "4                                                 96  \n",
      "5                                                 88  \n",
      "6                                                 79  \n",
      "7                                                 77  \n",
      "8                                                 68  \n",
      "9                                                 67  \n"
     ]
    }
   ],
   "source": [
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating. \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_womens_odi_teams():\n",
    "    women_odi_team_ranking = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\").content\n",
    "\n",
    "    \n",
    "    if women_odi_team_ranking:\n",
    "        soup = BeautifulSoup(women_odi_team_ranking, 'html.parser')\n",
    "\n",
    "        teams_data = []\n",
    "        table = soup.find('table', class_='table')\n",
    "        rows = table.find_all('tr')[1:11]\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            team_name = columns[1].text.strip()\n",
    "            matches = columns[2].text\n",
    "            points = columns[3].text\n",
    "            rating = columns[4].text\n",
    "            teams_data.append({'Team': team_name, 'Matches': matches, 'Points': points, 'Rating': rating})\n",
    "\n",
    "        teams_df = pd.DataFrame(teams_data)\n",
    "        print(\"Top 10 Women's ODI Teams:\")\n",
    "        print(teams_df)\n",
    "\n",
    "scrape_womens_odi_teams()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc299f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Women's ODI Batting Players:\n",
      "             Player Team Rating\n",
      "0    Australia\\nAUS   21  3,429\n",
      "1      England\\nENG   23  2,991\n",
      "2  South Africa\\nSA   21  2,446\n",
      "3        India\\nIND   18  1,745\n",
      "4   New Zealand\\nNZ   21  2,014\n",
      "5   West Indies\\nWI   20  1,768\n",
      "6     Sri Lanka\\nSL    9    714\n",
      "7   Bangladesh\\nBAN   14  1,074\n",
      "8     Thailand\\nTHA   11    753\n",
      "9     Pakistan\\nPAK   24  1,602\n"
     ]
    }
   ],
   "source": [
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "def womens_odi_batting():\n",
    "    womens_odi_batting = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\").content\n",
    "\n",
    "    if womens_odi_batting:\n",
    "        soup = BeautifulSoup(womens_odi_batting, 'html.parser')\n",
    "\n",
    "        batting_players_data = []\n",
    "        table = soup.find('table', class_='table')\n",
    "        rows = table.find_all('tr')[1:11]  \n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            player_name = columns[1].text.strip()\n",
    "            team = columns[2].text.strip()\n",
    "            rating = columns[3].text\n",
    "            batting_players_data.append({'Player': player_name, 'Team': team, 'Rating': rating})\n",
    "\n",
    "        batting_players_df = pd.DataFrame(batting_players_data)\n",
    "        print(\"\\nTop 10 Women's ODI Batting Players:\")\n",
    "        print(batting_players_df)\n",
    "    \n",
    "womens_odi_batting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d38c41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Women's ODI All-Rounders:\n",
      "                 Player Team   Rating\n",
      "0        Marizanne Kapp   SA  \\n385\\n\n",
      "1      Ashleigh Gardner  AUS      377\n",
      "2  Natalie Sciver-Brunt  ENG      360\n",
      "3       Hayley Matthews   WI      358\n",
      "4           Amelia Kerr   NZ      346\n",
      "5         Deepti Sharma  IND      312\n",
      "6          Ellyse Perry  AUS      282\n",
      "7              Nida Dar  PAK      240\n",
      "8         Jess Jonassen  AUS      227\n",
      "9         Sophie Devine   NZ      227\n"
     ]
    }
   ],
   "source": [
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "def womens_odi_allrounders():\n",
    "    womens_odi_player = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\").content\n",
    "\n",
    "    if womens_odi_player:\n",
    "        soup = BeautifulSoup(womens_odi_player, 'html.parser')\n",
    "\n",
    "        allrounders_data = []\n",
    "        table = soup.find('table', class_='table')\n",
    "        rows = table.find_all('tr')[1:11] \n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            player_name = columns[1].text.strip()\n",
    "            team = columns[2].text.strip()\n",
    "            rating = columns[3].text\n",
    "            allrounders_data.append({'Player': player_name, 'Team': team, 'Rating': rating})\n",
    "\n",
    "        allrounders_df = pd.DataFrame(allrounders_data)\n",
    "        print(\"\\nTop 10 Women's ODI All-Rounders:\")\n",
    "        print(allrounders_df)\n",
    "    \n",
    "womens_odi_allrounders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df8c46",
   "metadata": {},
   "source": [
    "### 5) Write a python program to scrape mentioned news details from https://www.cnbc.com/2023/12/02/how-rio-tinto-is-poised-to-benefit-from-the-ev-boom.html and make data frame-\n",
    "i) Headline ii) Time iii) NewsLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bc4616c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  \\\n",
      "0  https://www.cnbc.com/2023/12/02/how-rio-tinto-...   \n",
      "\n",
      "                                                   1  \\\n",
      "0  How $100 billion mining giant Rio Tinto is poi...   \n",
      "\n",
      "                                      2  \n",
      "0  Published Sat, Dec 2 20238:30 AM EST  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "def scrape_news_details():\n",
    "    \n",
    "    url = \"https://www.cnbc.com/2023/12/02/how-rio-tinto-is-poised-to-benefit-from-the-ev-boom.html\"\n",
    "    newscontent = requests.get(url).content\n",
    "    if newscontent:\n",
    "        soup = BeautifulSoup(newscontent, 'html.parser')\n",
    "\n",
    "        news_data = []\n",
    "        headline = soup.find('h1', class_='ArticleHeader-headline').text.strip()\n",
    "        time = soup.find('time').text.strip()\n",
    "        \n",
    "        news_data.append({headline,time, url})\n",
    "\n",
    "        article_df = pd.DataFrame(news_data)\n",
    "        print(article_df)\n",
    "\n",
    "scrape_news_details()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1baaa99",
   "metadata": {},
   "source": [
    "### 6) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame-\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e947c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Paper Title\n",
      "0  Reward is enough\n"
     ]
    }
   ],
   "source": [
    "# Work in progress , got the value for title for first element, will continue working on it\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_most_downloaded_articles():\n",
    "    url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "    if content:\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        articles_data = []\n",
    "        articles = soup.find_all('ul', class_='sc-9zxyh7-0')\n",
    "        for article in articles:\n",
    "            title = article.find('h2', class_='sc-1qrq3sd-1').text.strip()\n",
    "            articles_data.append({\n",
    "                 title})\n",
    "\n",
    "        articles_df = pd.DataFrame(articles_data)\n",
    "        print(articles_df)\n",
    "\n",
    "scrape_most_downloaded_articles()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361d0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
