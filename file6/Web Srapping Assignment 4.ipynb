{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122119b9",
   "metadata": {},
   "source": [
    "### 1)Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A)Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30f5818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.84</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.34</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.86</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.55</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.17</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.13</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.79</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.63</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.12</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.04</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.00</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.57</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.51</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.24</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.98</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.94</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.93</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.90</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.82</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.81</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.75</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.71</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.68</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.65</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.63</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[50]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.61</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.58</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.57</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.54</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.52</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Video name  \\\n",
       "0                             \"Baby Shark Dance\"[6]   \n",
       "1                                    \"Despacito\"[9]   \n",
       "2                        \"Johny Johny Yes Papa\"[17]   \n",
       "3                                   \"Bath Song\"[18]   \n",
       "4                                \"Shape of You\"[19]   \n",
       "5                               \"See You Again\"[22]   \n",
       "6                           \"Wheels on the Bus\"[27]   \n",
       "7                 \"Phonics Song with Two Words\"[28]   \n",
       "8                                 \"Uptown Funk\"[29]   \n",
       "9   \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10                              \"Gangnam Style\"[31]   \n",
       "11   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12                             \"Dame Tu Cosita\"[37]   \n",
       "13                                     \"Axel F\"[38]   \n",
       "14                                      \"Sugar\"[39]   \n",
       "15                             \"Counting Stars\"[40]   \n",
       "16                                       \"Roar\"[41]   \n",
       "17                        \"Baa Baa Black Sheep\"[42]   \n",
       "18                             \"Lakdi Ki Kathi\"[43]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "20                                      \"Sorry\"[45]   \n",
       "21                          \"Thinking Out Loud\"[46]   \n",
       "22          \"Humpty the train on a fruits ride\"[47]   \n",
       "23                                 \"Dark Horse\"[48]   \n",
       "24                                    \"Perfect\"[49]   \n",
       "25                      \"Shree Hanuman Chalisa\"[50]   \n",
       "26                                 \"Let Her Go\"[51]   \n",
       "27                                      \"Faded\"[52]   \n",
       "28                             \"Girls Like You\"[53]   \n",
       "29                                    \"Lean On\"[54]   \n",
       "\n",
       "                                             Uploader  Views  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories  13.84   \n",
       "1                                          Luis Fonsi   8.34   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.86   \n",
       "3                          Cocomelon - Nursery Rhymes   6.55   \n",
       "4                                          Ed Sheeran   6.17   \n",
       "5                                         Wiz Khalifa   6.13   \n",
       "6                          Cocomelon - Nursery Rhymes   5.79   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   5.63   \n",
       "8                                         Mark Ronson   5.12   \n",
       "9                                         Miroshka TV   5.04   \n",
       "10                                                Psy   5.00   \n",
       "11                                         Get Movies   4.57   \n",
       "12                                      Ultra Records   4.51   \n",
       "13                                         Crazy Frog   4.24   \n",
       "14                                           Maroon 5   3.98   \n",
       "15                                        OneRepublic   3.94   \n",
       "16                                         Katy Perry   3.93   \n",
       "17                         Cocomelon - Nursery Rhymes   3.90   \n",
       "18                                       Jingle Toons   3.82   \n",
       "19                                            Shakira   3.81   \n",
       "20                                      Justin Bieber   3.75   \n",
       "21                                         Ed Sheeran   3.71   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.68   \n",
       "23                                         Katy Perry   3.65   \n",
       "24                                         Ed Sheeran   3.63   \n",
       "25                              T-Series Bhakti Sagar   3.61   \n",
       "26                                          Passenger   3.58   \n",
       "27                                        Alan Walker   3.57   \n",
       "28                                           Maroon 5   3.54   \n",
       "29                               Major Lazer Official   3.52   \n",
       "\n",
       "                 Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18      June 14, 2018  \n",
       "19       June 4, 2010  \n",
       "20   October 22, 2015  \n",
       "21    October 7, 2014  \n",
       "22   January 26, 2018  \n",
       "23  February 20, 2014  \n",
       "24   November 9, 2017  \n",
       "25       May 10, 2011  \n",
       "26      July 25, 2012  \n",
       "27   December 3, 2015  \n",
       "28       May 31, 2018  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")    \n",
    "time.sleep(3)    \n",
    "\n",
    "names =[]\n",
    "uploaders =[]\n",
    "views =[]\n",
    "dates = []\n",
    "\n",
    "\n",
    "try:\n",
    "    video_names_elements = driver.find_elements (By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "    for i in video_names_elements :\n",
    "        names.append(i.text)\n",
    "    \n",
    "    uploader_element = driver.find_elements (By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "    for i in uploader_element :\n",
    "        uploaders.append(i.text)\n",
    "    \n",
    "    views_element = driver.find_elements (By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "    for i in views_element :\n",
    "        views.append(i.text)      \n",
    "\n",
    "    date_element = driver.find_elements (By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "    for i in date_element :\n",
    "        dates.append(i.text)      \n",
    "        \n",
    "finally:\n",
    "    driver.close()\n",
    "    \n",
    "print(len(names),len(uploaders),len(views),len(dates))\n",
    "df = pd.DataFrame({'Video name':names,'Uploader':uploaders,\"Views\":views,\"Date\":dates})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6518e",
   "metadata": {},
   "source": [
    "### 2) Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "459efaa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series name</th>\n",
       "      <th>Place</th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2 JANUARY, 2024</td>\n",
       "      <td>8:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Newlands,</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>3 JANUARY, 2024</td>\n",
       "      <td>8:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>DY Patil Stadium,</td>\n",
       "      <td>NAVI MUMBAI</td>\n",
       "      <td>5 JANUARY, 2024</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>DY Patil Stadium,</td>\n",
       "      <td>NAVI MUMBAI</td>\n",
       "      <td>7 JANUARY, 2024</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>DY Patil Stadium,</td>\n",
       "      <td>NAVI MUMBAI</td>\n",
       "      <td>9 JANUARY, 2024</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>11 JANUARY, 2024</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>Indore</td>\n",
       "      <td>14 JANUARY, 2024</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>17 JANUARY, 2024</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Rajiv Gandhi International Stadium,</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>25 JANUARY, 2024</td>\n",
       "      <td>4:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>2 FEBRUARY, 2024</td>\n",
       "      <td>4:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>15 FEBRUARY, 2024</td>\n",
       "      <td>4:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>JSCA International Stadium Complex,</td>\n",
       "      <td>Ranchi</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>4:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>Dharamsala</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>4:00 AM GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Series name  \\\n",
       "0   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "1      INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "2   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "3   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "4   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "5       AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "6       AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "7       AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "8           ENGLAND TOUR OF INDIA 2023-24   \n",
       "9           ENGLAND TOUR OF INDIA 2023-24   \n",
       "10          ENGLAND TOUR OF INDIA 2023-24   \n",
       "11          ENGLAND TOUR OF INDIA 2023-24   \n",
       "12          ENGLAND TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                                Place                 \\\n",
       "0                                   Wankhede Stadium,         Mumbai   \n",
       "1                                           Newlands,      Cape Town   \n",
       "2                                   DY Patil Stadium,    NAVI MUMBAI   \n",
       "3                                   DY Patil Stadium,    NAVI MUMBAI   \n",
       "4                                   DY Patil Stadium,    NAVI MUMBAI   \n",
       "5       Punjab Cricket Association IS Bindra Stadium,         Mohali   \n",
       "6                             Holkar Cricket Stadium,         Indore   \n",
       "7                              M Chinnaswamy Stadium,      Bengaluru   \n",
       "8                 Rajiv Gandhi International Stadium,      Hyderabad   \n",
       "9   Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,  Visakhapatnam   \n",
       "10            Saurashtra Cricket Association Stadium,         Rajkot   \n",
       "11                JSCA International Stadium Complex,         Ranchi   \n",
       "12      Himachal Pradesh Cricket Association Stadium,     Dharamsala   \n",
       "\n",
       "                 Date         Time  \n",
       "0     2 JANUARY, 2024  8:00 AM GMT  \n",
       "1     3 JANUARY, 2024  8:00 AM GMT  \n",
       "2     5 JANUARY, 2024  1:30 PM GMT  \n",
       "3     7 JANUARY, 2024  1:30 PM GMT  \n",
       "4     9 JANUARY, 2024  1:30 PM GMT  \n",
       "5    11 JANUARY, 2024  1:30 PM GMT  \n",
       "6    14 JANUARY, 2024  1:30 PM GMT  \n",
       "7    17 JANUARY, 2024  1:30 PM GMT  \n",
       "8    25 JANUARY, 2024  4:00 AM GMT  \n",
       "9    2 FEBRUARY, 2024  4:00 AM GMT  \n",
       "10  15 FEBRUARY, 2024  4:00 AM GMT  \n",
       "11  23 FEBRUARY, 2024  4:00 AM GMT  \n",
       "12      7 MARCH, 2024  4:00 AM GMT  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")    \n",
    "time.sleep(3)   \n",
    "\n",
    "series_name = []\n",
    "ground = []\n",
    "city = []\n",
    "date = []\n",
    "time_note = []\n",
    "try:\n",
    "    fixture_page = driver.find_element(By.XPATH,'//a[contains(text(), \"Fixtures\")]')\n",
    "    fixture_page.click()\n",
    "    time.sleep(5)   \n",
    "    more_button_elememt = driver.find_element(By.XPATH,'//button[@class=\"match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3 morematches\"]')\n",
    "    more_button_elememt.click()\n",
    "\n",
    "    fixture_name_element = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "\n",
    "    for i in fixture_name_element :\n",
    "        series_name.append(i.text)\n",
    "        \n",
    "    fixture_ground_element = driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]/span[1]')\n",
    "    fixture_city_element = driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]/span[2]')\n",
    "\n",
    "    for i in fixture_ground_element :\n",
    "        ground.append(i.text)\n",
    "    \n",
    "    for i in fixture_city_element :\n",
    "        city.append(i.text)\n",
    "    \n",
    "    \n",
    "    fixture_date_element = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "\n",
    "    for i in fixture_date_element :\n",
    "        date.append(i.text)\n",
    "        \n",
    "    \n",
    "    \n",
    "    fixture_time_note_element = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "\n",
    "    for i in fixture_time_note_element :\n",
    "        time_note.append(i.text)\n",
    "        \n",
    "finally:\n",
    "    driver.close()\n",
    "    \n",
    "print(len(series_name))\n",
    "df = pd.DataFrame({'Series name':series_name,'Place':ground,'':city,'Date':date,'Time':time_note})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414c4fa",
   "metadata": {},
   "source": [
    "### 5)Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details: A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f36f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>weeks on board note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last Christmas</td>\n",
       "      <td>Wham!</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>Burl Ives</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>El Amor de Su Vida</td>\n",
       "      <td>Grupo Frontera &amp; Grupo Firme</td>\n",
       "      <td>-</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Standing Next To You</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Man Made A Bar</td>\n",
       "      <td>Morgan Wallen Featuring Eric Church</td>\n",
       "      <td>-</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Que Onda</td>\n",
       "      <td>Calle 24 x Chino Pacas x Fuerza Regida</td>\n",
       "      <td>98</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Great Gatsby</td>\n",
       "      <td>Rod Wave</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song Name                             Artist Name  \\\n",
       "0   Rockin' Around The Christmas Tree                              Brenda Lee   \n",
       "1     All I Want For Christmas Is You                            Mariah Carey   \n",
       "2                    Jingle Bell Rock                             Bobby Helms   \n",
       "3                      Last Christmas                                   Wham!   \n",
       "4             A Holly Jolly Christmas                               Burl Ives   \n",
       "..                                ...                                     ...   \n",
       "95                 El Amor de Su Vida            Grupo Frontera & Grupo Firme   \n",
       "96               Standing Next To You                               Jung Kook   \n",
       "97                     Man Made A Bar     Morgan Wallen Featuring Eric Church   \n",
       "98                           Que Onda  Calle 24 x Chino Pacas x Fuerza Regida   \n",
       "99                       Great Gatsby                                Rod Wave   \n",
       "\n",
       "   Last Week Rank Peak Rank weeks on board note  \n",
       "0               2         1                  58  \n",
       "1               1         1                  65  \n",
       "2               3         3                  56  \n",
       "3               4         4                  38  \n",
       "4               5         4                  39  \n",
       "..            ...       ...                 ...  \n",
       "95              -        68                  16  \n",
       "96             79         5                   8  \n",
       "97              -        15                  14  \n",
       "98             98        61                  13  \n",
       "99             99        30                  14  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https:/www.billboard.com/\")    \n",
    "time.sleep(3)   \n",
    "\n",
    "accept_button = driver.find_element(By.ID,\"onetrust-accept-btn-handler\")\n",
    "accept_button.click()\n",
    "\n",
    "charts_button = driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]\")\n",
    "charts_button.click()\n",
    "time.sleep(6)  \n",
    "\n",
    "\n",
    "view_chart_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//div[@class=\"lrv-u-flex lrv-u-align-items-center lrv-u-padding-t-2 lrv-u-padding-b-1 lrv-u-padding-t-150@mobile-max\"]/div[2]/span/a'))\n",
    ")\n",
    "\n",
    "\n",
    "view_chart_button.click()\n",
    "time.sleep(3)  \n",
    "\n",
    "\n",
    "song_name = []\n",
    "artist_name = []\n",
    "lastweeke_rank = []\n",
    "peak_rank = []\n",
    "weeks_on_board_note = []\n",
    "\n",
    "try:\n",
    "   \n",
    "    songname_element = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li/h3')      #to scrap name of laptop names        \n",
    "    for i in songname_element:\n",
    "        song_name.append(i.text)\n",
    "    \n",
    "    artist_element = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[1]/span')      #to scrap name of laptop names        \n",
    "    for i in artist_element:\n",
    "        artist_name.append(i.text)\n",
    "   \n",
    "    lastweeke_rank_element = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[4]/span')      #to scrap name of laptop names        \n",
    "    for i in lastweeke_rank_element:\n",
    "        lastweeke_rank.append(i.text)\n",
    "        \n",
    "    peak_rank_element = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[5]/span')      #to scrap name of laptop names        \n",
    "    for i in peak_rank_element:\n",
    "        peak_rank.append(i.text)\n",
    "    \n",
    "    weeks_on_board_note_element = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[6]/span')      #to scrap name of laptop names        \n",
    "    for i in weeks_on_board_note_element:\n",
    "        weeks_on_board_note.append(i.text)\n",
    "    \n",
    "\n",
    "finally:\n",
    "    driver.close()\n",
    "\n",
    "print(len(song_name),len(artist_name),len(lastweeke_rank),len(peak_rank),len(weeks_on_board_note_element))\n",
    "df = pd.DataFrame({'Song Name':song_name,'Artist Name':artist_name,'Last Week Rank':lastweeke_rank,'Peak Rank':peak_rank,'weeks on board note':weeks_on_board_note})\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736b648",
   "metadata": {},
   "source": [
    "### 6)  Scrape the details of Highest selling novels.\n",
    "A) Book name B) Author name C) Volumes sold D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68c5c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>volumes sell</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   volumes sell        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")    \n",
    "time.sleep(3)    \n",
    "\n",
    "\n",
    "book_name =[]\n",
    "author_name =[]\n",
    "volumes_sold =[]\n",
    "publisher  = []\n",
    "genre = []\n",
    "\n",
    "try:\n",
    "    title = driver.find_elements (By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in title :\n",
    "        book_name.append(i.text)\n",
    "        \n",
    "    author_name_elements = driver.find_elements (By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author_name_elements :\n",
    "        author_name.append(i.text)\n",
    "        \n",
    "    volumes_sold_element = driver.find_elements (By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in volumes_sold_element :\n",
    "        volumes_sold.append(i.text)\n",
    "        \n",
    "    publisher_element = driver.find_elements (By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher_element :\n",
    "        publisher.append(i.text)\n",
    "        \n",
    "    genre_element = driver.find_elements (By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre_element :\n",
    "        genre.append(i.text)\n",
    "\n",
    "    \n",
    "finally:\n",
    "    driver.close()\n",
    "    \n",
    "print(len(book_name),len(author_name),len(volumes_sold),len(publisher),len(genre))\n",
    "df = pd.DataFrame({'Name':book_name,'Author':author_name,'volumes sell':volumes_sold,'Publisher':publisher,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86a770",
   "metadata": {},
   "source": [
    "### 4) Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description C) Contributors count\n",
    "D) Language used\n",
    "5.\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef396b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>langauge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlabonne / llm-course</td>\n",
       "      <td>Course to get into Large Language Models (LLMs...</td>\n",
       "      <td>7,302</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donnemartin / system-design-primer</td>\n",
       "      <td>Learn how to design large-scale systems. Prep ...</td>\n",
       "      <td>240,211</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KRTirtho / spotube</td>\n",
       "      <td>🎧 Open source Spotify client that doesn't requ...</td>\n",
       "      <td>9,173</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>myshell-ai / OpenVoice</td>\n",
       "      <td>Instant voice cloning by MyShell. Join our Dis...</td>\n",
       "      <td>1,655</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie-web / movie-web</td>\n",
       "      <td>A small web app for watching movies and shows ...</td>\n",
       "      <td>12,897</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tyxsspa / AnyText</td>\n",
       "      <td>No description available</td>\n",
       "      <td>1,098</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AntonioErdeljac / next-auth-v5-advanced-guide</td>\n",
       "      <td>No description available</td>\n",
       "      <td>195</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thelastoutpostworkshop / gpio_viewer</td>\n",
       "      <td>GPIOViewer Arduino Library to see live GPIO Pi...</td>\n",
       "      <td>287</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anoma / namada</td>\n",
       "      <td>Rust implementation of Namada, a Proof-of-Stak...</td>\n",
       "      <td>2,134</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>janhq / jan</td>\n",
       "      <td>Jan is an open source alternative to ChatGPT t...</td>\n",
       "      <td>1,577</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DLYuanGod / TinyGPT-V</td>\n",
       "      <td>TinyGPT-V: Efficient Multimodal Large Language...</td>\n",
       "      <td>310</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>freeCodeCamp / freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>380,621</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>twentyhq / twenty</td>\n",
       "      <td>Building a modern alternative to Salesforce, p...</td>\n",
       "      <td>7,242</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>firefly-iii / firefly-iii</td>\n",
       "      <td>Firefly III: a personal finances manager</td>\n",
       "      <td>12,209</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UdaraJay / Pile</td>\n",
       "      <td>Desktop app for digital journaling.</td>\n",
       "      <td>885</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lllyasviel / Fooocus</td>\n",
       "      <td>Focus on prompting and generating</td>\n",
       "      <td>27,378</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TheAlgorithms / C-Plus-Plus</td>\n",
       "      <td>Collection of various algorithms in mathematic...</td>\n",
       "      <td>27,474</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Koenkk / zigbee2mqtt</td>\n",
       "      <td>Zigbee 🐝 to MQTT bridge 🌉, get rid of your pro...</td>\n",
       "      <td>10,440</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tailcallhq / tailcall</td>\n",
       "      <td>A high-performance no-code GraphQL backend</td>\n",
       "      <td>421</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ublue-os / bazzite</td>\n",
       "      <td>Bazzite is an OCI image that serves as an alte...</td>\n",
       "      <td>1,711</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>commaai / openpilot</td>\n",
       "      <td>openpilot is an open source driver assistance ...</td>\n",
       "      <td>45,121</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tiann / KernelSU</td>\n",
       "      <td>A Kernel based root solution for Android</td>\n",
       "      <td>5,728</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dvmazur / mixtral-offloading</td>\n",
       "      <td>Run Mixtral-8x7B models in Colab or consumer d...</td>\n",
       "      <td>1,106</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jordan-cutler / path-to-senior-engineer-handbook</td>\n",
       "      <td>All the resources you need to get to Senior En...</td>\n",
       "      <td>5,303</td>\n",
       "      <td>No Langauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>darktable-org / darktable</td>\n",
       "      <td>darktable is an open source photography workfl...</td>\n",
       "      <td>8,332</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                              mlabonne / llm-course   \n",
       "1                 donnemartin / system-design-primer   \n",
       "2                                 KRTirtho / spotube   \n",
       "3                             myshell-ai / OpenVoice   \n",
       "4                              movie-web / movie-web   \n",
       "5                                  tyxsspa / AnyText   \n",
       "6      AntonioErdeljac / next-auth-v5-advanced-guide   \n",
       "7               thelastoutpostworkshop / gpio_viewer   \n",
       "8                                     anoma / namada   \n",
       "9                                        janhq / jan   \n",
       "10                             DLYuanGod / TinyGPT-V   \n",
       "11                       freeCodeCamp / freeCodeCamp   \n",
       "12                                 twentyhq / twenty   \n",
       "13                         firefly-iii / firefly-iii   \n",
       "14                                   UdaraJay / Pile   \n",
       "15                              lllyasviel / Fooocus   \n",
       "16                       TheAlgorithms / C-Plus-Plus   \n",
       "17                              Koenkk / zigbee2mqtt   \n",
       "18                             tailcallhq / tailcall   \n",
       "19                                ublue-os / bazzite   \n",
       "20                               commaai / openpilot   \n",
       "21                                  tiann / KernelSU   \n",
       "22                      dvmazur / mixtral-offloading   \n",
       "23  jordan-cutler / path-to-senior-engineer-handbook   \n",
       "24                         darktable-org / darktable   \n",
       "\n",
       "                                          Description Contributors  \\\n",
       "0   Course to get into Large Language Models (LLMs...        7,302   \n",
       "1   Learn how to design large-scale systems. Prep ...      240,211   \n",
       "2   🎧 Open source Spotify client that doesn't requ...        9,173   \n",
       "3   Instant voice cloning by MyShell. Join our Dis...        1,655   \n",
       "4   A small web app for watching movies and shows ...       12,897   \n",
       "5                            No description available        1,098   \n",
       "6                            No description available          195   \n",
       "7   GPIOViewer Arduino Library to see live GPIO Pi...          287   \n",
       "8   Rust implementation of Namada, a Proof-of-Stak...        2,134   \n",
       "9   Jan is an open source alternative to ChatGPT t...        1,577   \n",
       "10  TinyGPT-V: Efficient Multimodal Large Language...          310   \n",
       "11  freeCodeCamp.org's open-source codebase and cu...      380,621   \n",
       "12  Building a modern alternative to Salesforce, p...        7,242   \n",
       "13           Firefly III: a personal finances manager       12,209   \n",
       "14                Desktop app for digital journaling.          885   \n",
       "15                  Focus on prompting and generating       27,378   \n",
       "16  Collection of various algorithms in mathematic...       27,474   \n",
       "17  Zigbee 🐝 to MQTT bridge 🌉, get rid of your pro...       10,440   \n",
       "18         A high-performance no-code GraphQL backend          421   \n",
       "19  Bazzite is an OCI image that serves as an alte...        1,711   \n",
       "20  openpilot is an open source driver assistance ...       45,121   \n",
       "21           A Kernel based root solution for Android        5,728   \n",
       "22  Run Mixtral-8x7B models in Colab or consumer d...        1,106   \n",
       "23  All the resources you need to get to Senior En...        5,303   \n",
       "24  darktable is an open source photography workfl...        8,332   \n",
       "\n",
       "            langauge  \n",
       "0   Jupyter Notebook  \n",
       "1             Python  \n",
       "2               Dart  \n",
       "3             Python  \n",
       "4         TypeScript  \n",
       "5             Python  \n",
       "6         TypeScript  \n",
       "7                C++  \n",
       "8               Rust  \n",
       "9         TypeScript  \n",
       "10            Python  \n",
       "11        TypeScript  \n",
       "12        TypeScript  \n",
       "13               PHP  \n",
       "14        JavaScript  \n",
       "15            Python  \n",
       "16               C++  \n",
       "17        JavaScript  \n",
       "18              Rust  \n",
       "19             Shell  \n",
       "20            Python  \n",
       "21            Kotlin  \n",
       "22            Python  \n",
       "23       No Langauge  \n",
       "24                 C  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/\")  \n",
    "time.sleep(3)\n",
    "\n",
    "menu = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "\n",
    "open_sourse_menu = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(open_sourse_menu).perform()\n",
    "time.sleep(1)  \n",
    "\n",
    "trending_element = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "trending_element.click()\n",
    "time.sleep(2)  \n",
    "\n",
    "\n",
    "repository_title = []\n",
    "repository_description = []\n",
    "contributors_count = []\n",
    "langauge_used = []\n",
    "try:\n",
    "    title_element = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')              \n",
    "\n",
    "    for i in title_element :\n",
    "        repository_title.append(i.text)\n",
    "\n",
    "    parent_element = driver.find_elements(By.XPATH, '//article[@class=\"Box-row\"]')\n",
    "    for i in parent_element :\n",
    "        try:\n",
    "            p_tags = i.find_element(By.XPATH, './/p')\n",
    "            repository_description.append(p_tags.text)\n",
    "           \n",
    "        except NoSuchElementException as e:\n",
    "            repository_description.append(\"No description available\")\n",
    "            \n",
    "    contributors_element = driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]//div[@class=\"f6 color-fg-muted mt-2\"]//a[@class=\"Link Link--muted d-inline-block mr-3\"][1]')      #to scrap name of laptop names        \n",
    "\n",
    "    for i in contributors_element :\n",
    "        contributors_count.append(i.text)\n",
    "        \n",
    "    for i in parent_element :\n",
    "        try:\n",
    "            langauge = i.find_element(By.XPATH, './/span[@itemprop=\"programmingLanguage\"]')\n",
    "            langauge_used.append(langauge.text)\n",
    "        except NoSuchElementException as e:\n",
    "            langauge_used.append(\"No Langauge\")\n",
    "\n",
    "finally:\n",
    "    driver.close()   \n",
    "print(len(repository_title),len(repository_description),len(contributors_count),len(langauge_used))\n",
    "df = pd.DataFrame({'Title':repository_title,'Description':repository_description,'Contributors':contributors_count,'langauge':langauge_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bf77b",
   "metadata": {},
   "source": [
    "### 8) Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21ca2d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 670 670 670 670 670 670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name                  Data type  \\\n",
       "0                                    Iris                    Tabular   \n",
       "1                        Dry Bean Dataset               Multivariate   \n",
       "2              Rice (Cammeo and Osmancik)               Multivariate   \n",
       "3                           Heart Disease               Multivariate   \n",
       "4                                   Adult               Multivariate   \n",
       "..                                    ...                        ...   \n",
       "665                                  Wine                    Tabular   \n",
       "666  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "667                              Diabetes  Multivariate, Time-Series   \n",
       "668                          Wine Quality               Multivariate   \n",
       "669                        Car Evaluation               Multivariate   \n",
       "\n",
       "                           Task              Attribute type         Instances  \\\n",
       "0                Classification                        Real     150 Instances   \n",
       "1                Classification               Integer, Real  13.61K Instances   \n",
       "2                Classification                        Real   3.81K Instances   \n",
       "3                Classification  Categorical, Integer, Real     303 Instances   \n",
       "4                Classification        Categorical, Integer  48.84K Instances   \n",
       "..                          ...                         ...               ...   \n",
       "665              Classification               Integer, Real     178 Instances   \n",
       "666              Classification                        Real     569 Instances   \n",
       "667              Classification        Categorical, Integer       1 Instances   \n",
       "668  Classification, Regression                        Real    4.9K Instances   \n",
       "669              Classification                 Categorical   1.73K Instances   \n",
       "\n",
       "    No of attribute       Year  \n",
       "0        4 Features   7/1/1988  \n",
       "1       16 Features  9/14/2020  \n",
       "2        7 Features  10/6/2019  \n",
       "3       13 Features   7/1/1988  \n",
       "4       14 Features   5/1/1996  \n",
       "..              ...        ...  \n",
       "665     13 Features   7/1/1991  \n",
       "666     30 Features  11/1/1995  \n",
       "667     20 Features        N/A  \n",
       "668     12 Features  10/7/2009  \n",
       "669      6 Features   6/1/1997  \n",
       "\n",
       "[670 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\" https://archive.ics.uci.edu/\")  \n",
    "time.sleep(3)\n",
    "\n",
    "accept_TC = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/div/div[2]/button')\n",
    "accept_TC.click()\n",
    "\n",
    "view_dataset_element= driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/footer/div[3]/a[2]')\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(view_dataset_element).perform()\n",
    "\n",
    "view_dataset_element.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "expand_all_element = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')\n",
    "expand_all_element.click()\n",
    "\n",
    "start = 0\n",
    "end = 67\n",
    "\n",
    "dataset_name = []\n",
    "data_type = []\n",
    "task = []\n",
    "attribute_type = []\n",
    "no_of_instances = []\n",
    "no_of_attribute = []\n",
    "year = []\n",
    "for page in range(start,end):\n",
    "    dataset = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]') \n",
    "    for i in dataset:\n",
    "        dataset_name.append(i.text)\n",
    "    \n",
    "    data_type_element = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span') \n",
    "    for i in data_type_element:\n",
    "        data_type.append(i.text)\n",
    "        \n",
    "    task_element = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span') \n",
    "    for i in task_element:\n",
    "        task.append(i.text)\n",
    "        \n",
    "    attribute_type_element = driver.find_elements(By.XPATH,'//table[@class=\"col-span-full my-2 table sm:col-start-2\"]/tbody/tr/td[2]') \n",
    "    for i in attribute_type_element:\n",
    "        attribute_type.append(i.text)\n",
    "        \n",
    "    instances_element = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span') \n",
    "    for i in instances_element:\n",
    "        no_of_instances.append(i.text)\n",
    "        \n",
    "    attribute_no = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span') \n",
    "    for i in attribute_no:\n",
    "        no_of_attribute.append(i.text)\n",
    "        \n",
    "    year_element = driver.find_elements(By.XPATH,'//table[@class=\"col-span-full my-2 table sm:col-start-2\"]/tbody/tr/td[3]') \n",
    "    for i in year_element:\n",
    "        year.append(i.text)\n",
    "    \n",
    "    time.sleep(2)    \n",
    "next_button = driver.find_element(By.XPATH, '//button[@class=\"btn-primary btn-sm btn\"][2]')\n",
    "next_button.click()\n",
    "time.sleep(2)\n",
    "    \n",
    "print(len(dataset_name),len(data_type),len(task),len(attribute_type),len(no_of_instances),len(no_of_attribute),len(year))\n",
    "\n",
    "df = pd.DataFrame({'Name':dataset_name,'Data type':data_type,'Task':task,'Attribute type':attribute_type,'Instances':no_of_instances,'No of attribute':no_of_attribute,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04852d",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details: A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9117d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above page is not exist and it's giving 404 error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb87d08",
   "metadata": {},
   "source": [
    "### 3) Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices E) Share(18-19) F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://statisticstimes.com/\")    \n",
    "time.sleep(3)   \n",
    "\n",
    "\n",
    "termsandconditions = driver.find_element(By.XPATH,'//a[@class=\"cc-btn cc-dismiss\"]')\n",
    "termsandconditions.click()\n",
    "\n",
    "economy = driver.find_element(By.XPATH,'//button[contains(text(), \"Economy\")]')\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(economy).perform()\n",
    "time.sleep(1)  \n",
    "\n",
    "\n",
    "\n",
    "economy_india_element =  driver.find_element(By.XPATH,'//button[contains(text(), \"Economy\")]/following-sibling::div//a[contains(text(), \"India\")]')\n",
    "economy_india_element.click()\n",
    "time.sleep(5)\n",
    "\n",
    "indian_states_button = driver.find_element(By.XPATH,'//a[contains(text(), \"GDP of Indian states\")]')\n",
    "indian_states_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "agreeTnC_button = driver.find_element(By.XPATH,'//button[@class=\" css-47sehv\"]')\n",
    "agreeTnC_button.click()\n",
    "\n",
    "rank = []\n",
    "state = [] \n",
    "GSDP_18_19 = []\n",
    "GSDP_19_20 = [] \n",
    "Share_18_19 = []\n",
    "GDP_billion =[]\n",
    "\n",
    "\n",
    "# not able to proceed further in this question because i am not able to close google ads through code \n",
    "# also data for year 18-19 is not present on the page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
