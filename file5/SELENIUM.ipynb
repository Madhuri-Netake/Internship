{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d096ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.16.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in ./anaconda3/lib/python3.10/site-packages (from selenium) (2022.12.7)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.23.1-py3-none-any.whl (448 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.3/448.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in ./anaconda3/lib/python3.10/site-packages (from selenium) (1.26.14)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in ./anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: idna in ./anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: sortedcontainers in ./anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./anaconda3/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "Successfully installed exceptiongroup-1.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.16.0 sniffio-1.3.0 trio-0.23.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9f6a0",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12d71409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Data Analyst</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>novel group</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>hire connect</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vacancy For Data Analyst</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Coordinator (Data Analyst) Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Project Coordinator (Data analyst) Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Data Analyst - Modeling &amp; Profiling</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data analyst - Java / Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - SQL/ Database Maintenance</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Data Analyst - Modeling &amp; Profiling</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst - Java/Python BANGALORE</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Business Data Analyst - Modeling &amp; Profiling</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hiring for data entry analyst work</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>global solutions..</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>ok lifecare private limited</td>\n",
       "      <td>1 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>opening data analyst -Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>provizor it services pvt. ltd.</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Big Data Business Analyst</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>cynosure corporate solutions..</td>\n",
       "      <td>7 to 12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Analyst Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Job Title        Location  \\\n",
       "0                         Marketing Data Analyst   Bangalore\\n+1   \n",
       "1                       Data Analyst Recruitment  Bangalore\\n+13   \n",
       "2                                   Data Analyst   Bangalore\\n+9   \n",
       "3                       Vacancy For Data Analyst  Bangalore\\n+13   \n",
       "4   Project Coordinator (Data Analyst) Bangalore       Bangalore   \n",
       "5   Project Coordinator (Data analyst) Bangalore       Bangalore   \n",
       "6   Business Data Analyst - Modeling & Profiling       Bangalore   \n",
       "7                   Data analyst - Java / Python       Bangalore   \n",
       "8                     Data Analyst - Java/Python       Bangalore   \n",
       "9       Data Analyst - SQL/ Database Maintenance       Bangalore   \n",
       "10  Business Data Analyst - Modeling & Profiling       Bangalore   \n",
       "11          Data Analyst - Java/Python BANGALORE       Bangalore   \n",
       "12  Business Data Analyst - Modeling & Profiling       Bangalore   \n",
       "13            hiring for data entry analyst work   Bangalore\\n+9   \n",
       "14                                  Data analyst   Bangalore\\n+9   \n",
       "15               opening data analyst -Bangalore       Bangalore   \n",
       "16                     Big Data Business Analyst   Bangalore\\n+1   \n",
       "17                          Data Analyst Vacancy  Bangalore\\n+14   \n",
       "18                          Data Analyst Vacancy  Bangalore\\n+14   \n",
       "19                         Clinical Data Analyst   Bangalore\\n+4   \n",
       "\n",
       "                              Company_name   Experience  \n",
       "0                              novel group   2 to 6 Yrs  \n",
       "1                        kavya interprises   0 to 4 Yrs  \n",
       "2                             hire connect    0 to 1 Yr  \n",
       "3                        kavya interprises   0 to 4 Yrs  \n",
       "4                      futures and careers   2 to 4 Yrs  \n",
       "5                      futures and careers   2 to 4 Yrs  \n",
       "6   boyen haddin consulting and technol...   2 to 6 Yrs  \n",
       "7   boyen haddin consulting and technol...  5 to 10 Yrs  \n",
       "8   boyen haddin consulting and technol...   2 to 6 Yrs  \n",
       "9   boyen haddin consulting and technol...   2 to 6 Yrs  \n",
       "10  boyen haddin consulting and technol...   2 to 6 Yrs  \n",
       "11  boyen haddin consulting and technol...   4 to 8 Yrs  \n",
       "12  boyen haddin consulting and technol...   2 to 6 Yrs  \n",
       "13                      global solutions..    0 to 1 Yr  \n",
       "14             ok lifecare private limited   1 to 5 Yrs  \n",
       "15          provizor it services pvt. ltd.   2 to 5 Yrs  \n",
       "16          cynosure corporate solutions..  7 to 12 Yrs  \n",
       "17                       divya interprises   0 to 4 Yrs  \n",
       "18                       divya interprises   0 to 4 Yrs  \n",
       "19                         quiscon biotech   0 to 2 Yrs  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.shine.com/new/job-search\")\n",
    "\n",
    "job_role = driver.find_element(By.CLASS_NAME, \"form-control\")\n",
    "job_role.send_keys('Data Analyst')\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "experience = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[1]/ul/li[3]/div/input[1]\")\n",
    "experience.send_keys('11')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[2]/div/button\")\n",
    "\n",
    "search_button.click()\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "# scraping Job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH, '//div[@class =\"jobCard_jobCard__jjUmu  white-box-border jobCard\" or @class=\"jobCard_jobCard__jjUmu active white-box-border jobCard\"]/div/h2/a') \n",
    "for i in title_tags:\n",
    "    title=i.text \n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements (By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags:\n",
    "    exp=i.text \n",
    "    experience_required.append(exp)\n",
    "\n",
    "\n",
    "\n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]') \n",
    "for i in location_tags:\n",
    "    location=i.text \n",
    "    job_location.append(location)\n",
    "\n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span') \n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append (company)\n",
    "\n",
    "print(len (job_title),len (job_location), len (company_name), len (experience_required))\n",
    "\n",
    "    \n",
    "df=pd.DataFrame ({'Job Title':job_title,'Location':job_location, 'Company_name' : company_name, 'Experience': experience_required})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829abfa4",
   "metadata": {},
   "source": [
    "### Q2:Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86c7259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>capgemini technology services india...</td>\n",
       "      <td>6 to 11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Business Intelligence</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist for Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>get hired</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Spark/Python/Redshift</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ibm india pvt. limited</td>\n",
       "      <td>10 to 12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist- Associate</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist- Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>the fashion cosmo</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist Urgent Recruitment</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist AI ML CV</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist AI ML NLP</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Phd Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist-Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>shiva hr services</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist - Business Intelligence</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job Title        Location  \\\n",
       "0            Data Scientist Urgent Vacancy  Bangalore\\n+13   \n",
       "1               Data Scientist Recruitment  Bangalore\\n+13   \n",
       "2                           Data scientist   Bangalore\\n+8   \n",
       "3   Data Scientist - Business Intelligence       Bangalore   \n",
       "4             Data Scientist for Bangalore       Bangalore   \n",
       "5   Data Scientist - Spark/Python/Redshift       Bangalore   \n",
       "6        Data Scientist - Machine Learning       Bangalore   \n",
       "7                Hiring For Data Scientist  Bangalore\\n+13   \n",
       "8                Hiring For Data Scientist  Bangalore\\n+13   \n",
       "9                           Data Scientist       Bangalore   \n",
       "10               Data Scientist- Associate       Bangalore   \n",
       "11                  Data Scientist Vacancy  Bangalore\\n+14   \n",
       "12               Data Scientist- Bangalore       Bangalore   \n",
       "13       Data Scientist Urgent Recruitment  Bangalore\\n+14   \n",
       "14                 Data Scientist AI ML CV       Bangalore   \n",
       "15                Data Scientist AI ML NLP       Bangalore   \n",
       "16                      Phd Data Scientist       Bangalore   \n",
       "17               Hiring For Data Scientist  Bangalore\\n+14   \n",
       "18                Data Scientist-Bangalore       Bangalore   \n",
       "19  Data Scientist - Business Intelligence       Bangalore   \n",
       "\n",
       "                              Company_name    Experience  \n",
       "0                        kavya interprises    0 to 4 Yrs  \n",
       "1                        kavya interprises    0 to 4 Yrs  \n",
       "2   capgemini technology services india...   6 to 11 Yrs  \n",
       "3   boyen haddin consulting and technol...    2 to 6 Yrs  \n",
       "4                                get hired    0 to 3 Yrs  \n",
       "5   boyen haddin consulting and technol...    4 to 8 Yrs  \n",
       "6   boyen haddin consulting and technol...    2 to 4 Yrs  \n",
       "7                        kavya interprises    0 to 4 Yrs  \n",
       "8                        kavya interprises    0 to 4 Yrs  \n",
       "9                   ibm india pvt. limited  10 to 12 Yrs  \n",
       "10                                jpmorgan    4 to 6 Yrs  \n",
       "11                       divya interprises    0 to 4 Yrs  \n",
       "12                       the fashion cosmo    0 to 3 Yrs  \n",
       "13                       divya interprises    0 to 4 Yrs  \n",
       "14                             bosch group    3 to 5 Yrs  \n",
       "15                             bosch group    3 to 5 Yrs  \n",
       "16                             bosch group    2 to 5 Yrs  \n",
       "17                       divya interprises    0 to 4 Yrs  \n",
       "18                       shiva hr services    0 to 3 Yrs  \n",
       "19  boyen haddin consulting and technol...    2 to 6 Yrs  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.shine.com/new/job-search\")\n",
    "\n",
    "job_role = driver.find_element(By.CLASS_NAME, \"form-control\")\n",
    "job_role.send_keys('Data Scientist')\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "experience = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[1]/ul/li[3]/div/input[1]\")\n",
    "experience.send_keys('11')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[2]/div/button\")\n",
    "\n",
    "search_button.click()\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "# scraping Job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH, '//div[@class =\"jobCard_jobCard__jjUmu  white-box-border jobCard\" or @class=\"jobCard_jobCard__jjUmu active white-box-border jobCard\"]/div/h2/a') \n",
    "for i in title_tags:\n",
    "    title=i.text \n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements (By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags:\n",
    "    exp=i.text \n",
    "    experience_required.append(exp)\n",
    "\n",
    "\n",
    "\n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]') \n",
    "for i in location_tags:\n",
    "    location=i.text \n",
    "    job_location.append(location)\n",
    "\n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span') \n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append (company)\n",
    "\n",
    "print(len (job_title),len (job_location), len (company_name), len (experience_required))\n",
    "\n",
    "    \n",
    "df=pd.DataFrame ({'Job Title':job_title,'Location':job_location, 'Company_name' : company_name, 'Experience': experience_required})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f64693",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage\n",
    " You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scrapeddata.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a9f521a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <input class=\"styled-checkbox\" id=\"filter_jFLoc_406\" type=\"checkbox\" name=\"location\" readonly=\"\" value=\"406\"> is not clickable at point (515, 221). Other element would receive the click: <label class=\"filter_filter_option_label__v_iAW\" for=\"filter_jFLoc_406\">...</label>\n  (Session info: chrome=120.0.6099.71)\nStacktrace:\n0   chromedriver                        0x00000001050444cc chromedriver + 4162764\n1   chromedriver                        0x000000010503c654 chromedriver + 4130388\n2   chromedriver                        0x0000000104c93bc0 chromedriver + 293824\n3   chromedriver                        0x0000000104ce10b4 chromedriver + 610484\n4   chromedriver                        0x0000000104cdf090 chromedriver + 602256\n5   chromedriver                        0x0000000104cdcb58 chromedriver + 592728\n6   chromedriver                        0x0000000104cdbb24 chromedriver + 588580\n7   chromedriver                        0x0000000104ccf994 chromedriver + 539028\n8   chromedriver                        0x0000000104ccf250 chromedriver + 537168\n9   chromedriver                        0x0000000104d19ab0 chromedriver + 842416\n10  chromedriver                        0x0000000104ccd6bc chromedriver + 530108\n11  chromedriver                        0x0000000104cce930 chromedriver + 534832\n12  chromedriver                        0x0000000105009df8 chromedriver + 3923448\n13  chromedriver                        0x000000010500e3cc chromedriver + 3941324\n14  chromedriver                        0x0000000104ff2028 chromedriver + 3825704\n15  chromedriver                        0x000000010500ef2c chromedriver + 3944236\n16  chromedriver                        0x0000000104fe46e4 chromedriver + 3770084\n17  chromedriver                        0x000000010502b970 chromedriver + 4061552\n18  chromedriver                        0x000000010502bae8 chromedriver + 4061928\n19  chromedriver                        0x000000010503c2d4 chromedriver + 4129492\n20  libsystem_pthread.dylib             0x0000000188e93fa8 _pthread_start + 148\n21  libsystem_pthread.dylib             0x0000000188e8eda0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     36\u001b[0m select_location \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyled-checkbox\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mselect_location\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:348\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <input class=\"styled-checkbox\" id=\"filter_jFLoc_406\" type=\"checkbox\" name=\"location\" readonly=\"\" value=\"406\"> is not clickable at point (515, 221). Other element would receive the click: <label class=\"filter_filter_option_label__v_iAW\" for=\"filter_jFLoc_406\">...</label>\n  (Session info: chrome=120.0.6099.71)\nStacktrace:\n0   chromedriver                        0x00000001050444cc chromedriver + 4162764\n1   chromedriver                        0x000000010503c654 chromedriver + 4130388\n2   chromedriver                        0x0000000104c93bc0 chromedriver + 293824\n3   chromedriver                        0x0000000104ce10b4 chromedriver + 610484\n4   chromedriver                        0x0000000104cdf090 chromedriver + 602256\n5   chromedriver                        0x0000000104cdcb58 chromedriver + 592728\n6   chromedriver                        0x0000000104cdbb24 chromedriver + 588580\n7   chromedriver                        0x0000000104ccf994 chromedriver + 539028\n8   chromedriver                        0x0000000104ccf250 chromedriver + 537168\n9   chromedriver                        0x0000000104d19ab0 chromedriver + 842416\n10  chromedriver                        0x0000000104ccd6bc chromedriver + 530108\n11  chromedriver                        0x0000000104cce930 chromedriver + 534832\n12  chromedriver                        0x0000000105009df8 chromedriver + 3923448\n13  chromedriver                        0x000000010500e3cc chromedriver + 3941324\n14  chromedriver                        0x0000000104ff2028 chromedriver + 3825704\n15  chromedriver                        0x000000010500ef2c chromedriver + 3944236\n16  chromedriver                        0x0000000104fe46e4 chromedriver + 3770084\n17  chromedriver                        0x000000010502b970 chromedriver + 4061552\n18  chromedriver                        0x000000010502bae8 chromedriver + 4061928\n19  chromedriver                        0x000000010503c2d4 chromedriver + 4129492\n20  libsystem_pthread.dylib             0x0000000188e93fa8 _pthread_start + 148\n21  libsystem_pthread.dylib             0x0000000188e8eda0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.shine.com/new/job-search\")\n",
    "\n",
    "job_role = driver.find_element(By.CLASS_NAME, \"form-control\")\n",
    "job_role.send_keys('Data Scientist')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[2]/div/button\")\n",
    "\n",
    "search_button.click()\n",
    "\n",
    "search_location = driver.find_element(By.CLASS_NAME,\"filter_filter_lists_items__wlFfo\")\n",
    "search_location.click()\n",
    "time.sleep(2)\n",
    "\n",
    "search_delhi = driver.find_element(By.CLASS_NAME,\"filter_filter_option_label__v_iAW\")\n",
    "search_delhi.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#sleep.time(2)\n",
    "\n",
    "location = driver.find_element(By.XPATH,'//li[@class=\"pr-20 mb-15\"]/input')\n",
    "location.send_keys('Delhi')\n",
    "time.sleep(2)\n",
    "\n",
    "select_location = driver.find_element(By.CLASS_NAME,\"styled-checkbox\")\n",
    "select_location.click()\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "# I am struggling to add the wait time in my program , looks like it's not able to find the location \n",
    "# input tag because till the time location filter is opening my program finished it's execution and it's getting\n",
    "# ElementClickInterceptedException  on click event for seleting Delhi checkbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ce4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3219be64",
   "metadata": {},
   "source": [
    "### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79da1ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discription</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBRACOLLECTION</td>\n",
       "      <td>₹123</td>\n",
       "      <td>Night Vision, Riding Glasses, UV Protection, O...</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC STAR</td>\n",
       "      <td>₹225</td>\n",
       "      <td>UV Protection, Riding Glasses Spectacle Sungla...</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹549</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (58)</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹501</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹69</td>\n",
       "      <td>UV Protection, Mirrored Aviator Sunglasses (58)</td>\n",
       "      <td>92% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>₹12,065</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (58)</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹645</td>\n",
       "      <td>UV Protection Wayfarer, Rectangular Sunglasses...</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹675</td>\n",
       "      <td>UV Protection Oval Sunglasses (63)</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>₹352</td>\n",
       "      <td>UV Protection Oval Sunglasses (60)</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>₹8,308</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand    Price  \\\n",
       "0    EBRACOLLECTION     ₹123   \n",
       "1           PC STAR     ₹225   \n",
       "2          Fastrack     ₹549   \n",
       "3          Fastrack     ₹501   \n",
       "4             NuVew      ₹69   \n",
       "..              ...      ...   \n",
       "115         Ray-Ban  ₹12,065   \n",
       "116          AISLIN     ₹645   \n",
       "117          AISLIN     ₹675   \n",
       "118        Roadster     ₹352   \n",
       "119         Ray-Ban   ₹8,308   \n",
       "\n",
       "                                           Discription Discount  \n",
       "0    Night Vision, Riding Glasses, UV Protection, O...  87% off  \n",
       "1    UV Protection, Riding Glasses Spectacle Sungla...  77% off  \n",
       "2               UV Protection Wayfarer Sunglasses (58)  50% off  \n",
       "3     UV Protection Rectangular Sunglasses (Free Size)  44% off  \n",
       "4      UV Protection, Mirrored Aviator Sunglasses (58)  92% off  \n",
       "..                                                 ...      ...  \n",
       "115         UV Protection Retro Square Sunglasses (58)  25% off  \n",
       "116  UV Protection Wayfarer, Rectangular Sunglasses...  70% off  \n",
       "117                 UV Protection Oval Sunglasses (63)  78% off  \n",
       "118                 UV Protection Oval Sunglasses (60)  67% off  \n",
       "119              UV Protection Aviator Sunglasses (58)  20% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/\")    #to open the Flipkart website\n",
    "\n",
    "search = driver.find_element(By.XPATH, '//input[@class=\"Pke_EE\"]')  #to Insert 'sunglasses' in search bar\n",
    "search.send_keys('sunglasses')\n",
    "close_pop_up  = driver.find_element(By.CLASS_NAME,'_30XB9F')   #to close login popup\n",
    "close_pop_up.click()\n",
    "search_button = driver.find_element(By.CLASS_NAME,'_2iLD__')  #to click on search button \n",
    "search_button.click()\n",
    "\n",
    "start = 0\n",
    "end = 3\n",
    "brand = []\n",
    "discription = []\n",
    "price = []\n",
    "discount = []\n",
    "for page in range(start,end):  #to scrap brand names\n",
    "    brand_name = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')              \n",
    "    for i in brand_name :\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    #to scarp product description     \n",
    "    product_discription = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\" or @class=\"IRpwTa\"]')              \n",
    "    for i in product_discription  :\n",
    "        discription.append(i.text)\n",
    "        \n",
    "    #to scarp product price   \n",
    "    product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')              \n",
    "    for i in product_price  :\n",
    "        price.append(i.text)\n",
    "    #to scarp product discount    \n",
    "    product_discount = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')              \n",
    "    for i in product_discount  :\n",
    "        discount.append(i.text)\n",
    "    \n",
    "    #to click on next button \n",
    "    next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "# creating a data frame\n",
    "df = pd.DataFrame ({'Brand':brand ,'Price':price,'Discription':discription,'Discount':discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333faa7",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product- reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e8c974e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>Product review</th>\n",
       "      <th>full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>very good camera quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Excellent Fabulous Adorable Iphone 11 Value fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanks Flipkart For this amazing deal! I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I switched to IOS for long term use and for be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>Good</td>\n",
       "      <td>only the name worth it with d price.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       Product review  \\\n",
       "0       5       Classy product   \n",
       "1       5     Perfect product!   \n",
       "2       5            Brilliant   \n",
       "3       5  Best in the market!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Wonderful   \n",
       "96      5   Highly recommended   \n",
       "97      4            Very Good   \n",
       "98      5       Classy product   \n",
       "99      3                 Good   \n",
       "\n",
       "                                         full review   \n",
       "0   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "1                                        Photos super  \n",
       "2                            very good camera quality  \n",
       "3                                         Good Camera  \n",
       "4   Feeling awesome after getting the delivery of ...  \n",
       "..                                                ...  \n",
       "95  Excellent Fabulous Adorable Iphone 11 Value fo...  \n",
       "96  Thanks Flipkart For this amazing deal! I had a...  \n",
       "97  I switched to IOS for long term use and for be...  \n",
       "98                 Outstanding performance this phone  \n",
       "99               only the name worth it with d price.  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZE3ENS&marketplace=FLIPKART&q=iphone%2011&sattr[]=color&sattr[]=storage&st=color\") \n",
    "# above given URL was not working(page not found)so i searched for the Mentioned product manually and then copied this URL from there\n",
    "\n",
    "\n",
    "start = 0\n",
    "end = 10\n",
    "rating = []\n",
    "review = [] \n",
    "full_review = []\n",
    "time.sleep(4)\n",
    "\n",
    "all_review = driver.find_element(By.XPATH,'//div[@class=\"_3UAT2v _16PBlm\"]')\n",
    "all_review.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "for page in range(start,end):\n",
    "    product_rating = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]') \n",
    "    for i in product_rating:\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    review_summary = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]') \n",
    "    for i in review_summary :\n",
    "        review.append(i.text) \n",
    "        \n",
    "    Full_review = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div[1]/div') \n",
    "    for i in  Full_review:\n",
    "        full_review.append(i.text) \n",
    "   \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\" and span/text()=\"Next\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "# creating a data frame    \n",
    "    \n",
    "df = pd.DataFrame ({'rating':rating,'Product review':review,'full review ':full_review})\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69185736",
   "metadata": {},
   "source": [
    "### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2aa972d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹406</td>\n",
       "      <td>Premium White Casual Shoes Sneakers For Men Sn...</td>\n",
       "      <td>BIRDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₹399</td>\n",
       "      <td>Megpar White New Stylish Look Comfortable Casu...</td>\n",
       "      <td>MEGPAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>₹299</td>\n",
       "      <td>Trending Stylish Casual Outdoor Sneakers Shoes...</td>\n",
       "      <td>URBANBOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>₹1,178</td>\n",
       "      <td>Puma Men White Black Colourblocked IDP Sneaker...</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>₹399</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>Deals4you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>₹347</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>aadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>₹4,600</td>\n",
       "      <td>Mirage Sport Asphalt Sneakers For Men</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>₹5,999</td>\n",
       "      <td>RS-X Efekt PRM Sneakers For Men</td>\n",
       "      <td>PUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>₹3,300</td>\n",
       "      <td>RC1975 022 Corporate Casuals For Men</td>\n",
       "      <td>RED CHIEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>₹999</td>\n",
       "      <td>Men's Fashion Sneakers Lace-Up Trainers Basket...</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price                                Product Description Product Brand\n",
       "0     ₹406  Premium White Casual Shoes Sneakers For Men Sn...         BIRDE\n",
       "1     ₹399  Megpar White New Stylish Look Comfortable Casu...        MEGPAR\n",
       "2     ₹299  Trending Stylish Casual Outdoor Sneakers Shoes...      URBANBOX\n",
       "3   ₹1,178  Puma Men White Black Colourblocked IDP Sneaker...          PUMA\n",
       "4     ₹399                                 Sneakers For Women     Deals4you\n",
       "..     ...                                                ...           ...\n",
       "95    ₹347                                   Sneakers For Men          aadi\n",
       "96  ₹4,600              Mirage Sport Asphalt Sneakers For Men          PUMA\n",
       "97  ₹5,999                    RS-X Efekt PRM Sneakers For Men          PUMA\n",
       "98  ₹3,300               RC1975 022 Corporate Casuals For Men     RED CHIEF\n",
       "99    ₹999  Men's Fashion Sneakers Lace-Up Trainers Basket...         asian\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/\")    #to open the Flipkart website\n",
    "\n",
    "search = driver.find_element(By.XPATH, '//input[@class=\"Pke_EE\"]')   # to scrap the search bar  \n",
    "search.send_keys('sneakers')   # to type 'sneakers' in to search bar\n",
    "\n",
    "close_pop_up  = driver.find_element(By.CLASS_NAME,'_30XB9F')    # to close login popup\n",
    "close_pop_up.click()\n",
    "\n",
    "search_button = driver.find_element(By.CLASS_NAME,'_2iLD__')   # to click on search Button \n",
    "search_button.click()\n",
    "\n",
    "# to scrap product brand,price,discription\n",
    "# to scrap the data from first 3 pages\n",
    "start = 0\n",
    "end = 3\n",
    "price = []\n",
    "discription = []  # creating empty lists to Store the brand,price,discription data\n",
    "brand = []\n",
    "numberofItems = 0\n",
    "\n",
    "while start <= numberofItems:  # while loop until it breaks on 100th element \n",
    "    \n",
    "    #useing relative xpath to scrap multiple price elements\n",
    "    product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "         \n",
    "    for i in product_price  :\n",
    "        if(len(price)<100): # on the single page it might have 40+ elements so check if length array reached to 100\n",
    "            price.append(i.text)\n",
    "            \n",
    "    #useing relative xpath to scrap multiple  product discription  elements\n",
    "    product_discription = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\" or  @class=\"IRpwTa\"]')    \n",
    "    #Above element have 2 different class for descriptions element so used OR condition \n",
    "    for i in product_discription  :\n",
    "        if(len(discription)<100):\n",
    "            discription.append(i.text)\n",
    "            \n",
    "    #useing relative xpath to scrap multiple  brand names      \n",
    "    brand_name = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')  \n",
    "         \n",
    "    for i in brand_name :\n",
    "        if(len(brand)<100):\n",
    "            brand.append(i.text)\n",
    "            \n",
    "    # to scrap the NEXT button \n",
    "    next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "\n",
    "    numberofItems = len(price)\n",
    "    if(numberofItems >= 100):  # if number items more than 100 then break the loop \n",
    "        break\n",
    "    else:\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    \n",
    "# creating a data frame    \n",
    "    \n",
    "df = pd.DataFrame ({'Price':price,'Product Description':discription,'Product Brand':brand})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cccf63",
   "metadata": {},
   "source": [
    "### Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f09aefd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Laptop 15s, AMD Ryzen 5 5500U, 15.6-inch (3...</td>\n",
       "      <td>₹39,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td>₹22,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS [SmartChoice] Vivobook 15, Intel Celeron ...</td>\n",
       "      <td>₹26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...</td>\n",
       "      <td>₹38,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...</td>\n",
       "      <td>₹44,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Aspire Lite 11th Gen Intel Core i3 Premiu...</td>\n",
       "      <td>₹28,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Laptop 15s, Intel Celeron, 15.6-inch (39.6 ...</td>\n",
       "      <td>₹28,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP 15s, AMD Ryzen 3 5300U, 15.6 inch(39.6cm) F...</td>\n",
       "      <td>₹32,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Aspire Lite AMD Ryzen 5 5500U Premium Thi...</td>\n",
       "      <td>₹39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell 15 Vostro 3520 Laptop, Intel Core i3-1115...</td>\n",
       "      <td>₹36,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title    price\n",
       "0  HP Laptop 15s, AMD Ryzen 5 5500U, 15.6-inch (3...  ₹39,800\n",
       "1  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...  ₹22,990\n",
       "2  ASUS [SmartChoice] Vivobook 15, Intel Celeron ...  ₹26,990\n",
       "3  HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...  ₹38,990\n",
       "4  HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...  ₹44,990\n",
       "5  Acer Aspire Lite 11th Gen Intel Core i3 Premiu...  ₹28,990\n",
       "6  HP Laptop 15s, Intel Celeron, 15.6-inch (39.6 ...  ₹28,490\n",
       "7  HP 15s, AMD Ryzen 3 5300U, 15.6 inch(39.6cm) F...  ₹32,390\n",
       "8  Acer Aspire Lite AMD Ryzen 5 5500U Premium Thi...  ₹39,990\n",
       "9  Dell 15 Vostro 3520 Laptop, Intel Core i3-1115...  ₹36,990"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in/\")   \n",
    "\n",
    "search_input = driver.find_element(By.XPATH,'//div[@class=\"nav-search-field \"]/input')\n",
    "search_input.send_keys('Laptop')\n",
    "search_submit = driver.find_element(By.XPATH,'//input[@class=\"nav-input nav-progressive-attribute\" and @type=\"submit\"]')\n",
    "search_submit.click()\n",
    "\n",
    "title = []\n",
    "price = []\n",
    "rating = []\n",
    "\n",
    "# scraping Title from the given page\n",
    "title_tags=driver.find_elements (By.XPATH, '//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')[1:11]\n",
    "for i in title_tags:\n",
    "    titleText=i.text \n",
    "    title.append(titleText)\n",
    "\n",
    "# scraping Title from the given page\n",
    "price_tags=driver.find_elements (By.XPATH, '//div[@class=\"a-section a-spacing-none a-spacing-top-micro puis-price-instructions-style\"]/div/div/a/span')[1:11]\n",
    "for i in price_tags:\n",
    "    priceText=i.text \n",
    "    price.append(priceText)\n",
    "#Could Not fetch the Rating of the product \n",
    "\n",
    "df = pd.DataFrame ({'Title':title,'price':price})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb43fc",
   "metadata": {},
   "source": [
    "### Q8: Write a python program to scrape data for Top 1000 Quotes of All Time. The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. ClickonTopQuotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f431142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>To love means loving the unlovable. To forgive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Be brave. Take risks. Nothing can substitute e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>If you really want to do something, you'll fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>It is neither wealth nor splendor; but tranqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>A thousand words will not leave so deep an imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title\n",
       "0    The essence of strategy is choosing what not t...\n",
       "1    One cannot and must not try to erase the past ...\n",
       "2    Patriotism means to stand by the country. It d...\n",
       "3    Death is something inevitable. When a man has ...\n",
       "4    You have to love a nation that celebrates its ...\n",
       "..                                                 ...\n",
       "895  To love means loving the unlovable. To forgive...\n",
       "896  Be brave. Take risks. Nothing can substitute e...\n",
       "897  If you really want to do something, you'll fin...\n",
       "898  It is neither wealth nor splendor; but tranqui...\n",
       "899  A thousand words will not leave so deep an imp...\n",
       "\n",
       "[900 rows x 1 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.azquotes.com/\")  \n",
    "\n",
    "top_qoutes = driver.find_element(By.XPATH,'//div[@class=\"mainmenu\"]//ul/li/a[text()=\"Top Quotes\"]')\n",
    "top_qoutes.click()\n",
    "time.sleep(1)\n",
    "\n",
    "start = 0\n",
    "title = []\n",
    "\n",
    "numberofItems = 0\n",
    "\n",
    "while start <= numberofItems:  # while loop until it breaks on 1000th element \n",
    "    \n",
    "    #useing relative xpath to scrap multiple title elements\n",
    "    qoute_title = driver.find_elements(By.XPATH,'//a[@class=\"title\"]') \n",
    "         \n",
    "    for i in qoute_title  :\n",
    "        if(len(price)<1000): # on the single page it might have 1000+ elements so check if length array reached to 100\n",
    "            title.append(i.text)\n",
    "            \n",
    "  \n",
    "            \n",
    "    # to scrap the NEXT button \n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "    except NoSuchElementException:\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "    numberofItems = len(title)\n",
    "    if(numberofItems >= 900):  # Not able to skip the click event on next button and Next button not availble on last page so collecting 900 titles \n",
    "        break\n",
    "    else:\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    \n",
    "# creating a data frame    \n",
    "    \n",
    "df = pd.DataFrame ({'Title':title})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e7b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdd0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
